[project]
name = "restaurant-menu-pricing"
version = "0.1.0"
description = "UberEats menu price prediction"
authors = [{ name = "ahmedshahriar", email = "ahmed.shahriar.sakib@gmail.com" }]
readme = "README.md"
requires-python = ">=3.11,<3.13"
dependencies = [
    # web crawling ETL dependencies
    "scrapy>=2.13.3,<3.0.0",
    "chompjs>=1.4.0,<2.0.0",
    "beautifulsoup4>=4.14.2,<5.0.0",
    "kagglehub>=0.3.13,<0.4.0",
    "pymongo>=4.15.2,<5.0.0",

    # machine learning dependencies
    "scikit-learn>=1.7.2,<2.0.0",
    "transformers>=4.56.2,<4.57.0", # broken metadata err v4.57.0 https://github.com/huggingface/transformers/issues/41331

    "torch>=2.8.0,<3.0.0",
    "xgboost>=3.0.5,<4.0.0",
    "lightgbm (>=4.6.0,<5.0.0)",
    "scikeras>=0.13.0,<0.14.0",
    "yellowbrick>=1.5,<2.0",
    "optuna>=4.5.0,<5.0.0",

    # MLflow and integrations
    "mlflow>=3.4.0,<4.0.0",
    "optuna-integration[mlflow] (>=4.5.0,<5.0.0)",

    # mlflow serve dependencies
    "virtualenv (>=20.35.3,<21.0.0)",
    "fastapi (>=0.119.0,<0.120.0)",

    # CLI, logging, validation
    "pydantic>=2.11.10,<3.0.0",
    "click (>=8.3.0,<9.0.0)",
    "loguru>=0.7.3,<0.8.0",
    "tqdm (>=4.67.1,<5.0.0)",

    # visualization dependencies
    "seaborn>=0.13.2,<0.14.0",
    "plotly (>=6.3.1,<7.0.0)",

    # Jupyter dependencies
    "notebook (>=7.4.7,<8.0.0)",
    "ipywidgets (>=8.1.7,<9.0.0)",
    "jupyter (>=1.1.1,<2.0.0)",
]

# OS-specific TensorFlow variants
[project.optional-dependencies]
tensorflow = [
    "tensorflow>=2.16.2,<3.0.0; platform_system == 'Linux' or platform_system == 'Windows'",
    "tensorflow-macos>=2.16.2,<3.0.0; platform_system == 'Darwin' and platform_machine == 'arm64'",
    "tensorflow-metal>=1.2.0,<2.0.0; platform_system == 'Darwin' and platform_machine == 'arm64'",
]

[tool.poetry]
package-mode = false

[tool.poetry.group.dev.dependencies]
ruff = "0.13.3"
pytest = "8.4.2"
pre-commit = "4.3.0"
python-dotenv = "^1.1.1"
pytest-cov = "^7.0.0"

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"

# (Optional) Poetry plugin requirement â€“ OK to keep even when using [project]
[tool.poetry.requires-plugins]
poethepoet = { version = "~0.35.0", extras = ["poetry_plugin"] }

[tool.ruff]
target-version = "py311"
line-length = 120
indent-width = 4
exclude = [".venv","venv","env","build","dist",".mypy_cache",".ruff_cache",".pytest_cache"]

[tool.ruff.format]
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.ruff.lint]
select = ["E","F","I","B","UP"]
ignore = ["E501"]
fixable = ["ALL"]

[tool.ruff.lint.isort]
known-first-party = ["application", "core"]

# ----------------------------------
# --- Poe the Poet Configuration ---
# ----------------------------------

[tool.poe.tasks]
hello = "echo 'Hello from Poe the Poet ðŸ‘‹'"

lint-check = "poetry run ruff check ."
format-check = "poetry run ruff format --check ."
lint-fix = "poetry run ruff check --fix ."
format-fix = "poetry run ruff format ."

# command must be run from the project root directory

# ---------------------------------------------
# --- Web Crawling to NoSQL Data Store/Json ---
# ---------------------------------------------

# Web crawling ETL tasks
# crawl restaurant locations, categories, and URLs
crawl-ubereats-categories = "poetry run scrapy crawl category_us"

# crawl restaurant menus and item details
crawl-ubereats = "poetry run scrapy crawl restaurant_us"

# -------------------------------------------------
# --- Export & Sampling from Crawled data store ---
# -------------------------------------------------

# DWH export pipeline
dwh-export = "dotenv run python -m tools.run dwh-export"

# generate a sample training dataset from the crawled data (stored in Kaggle)
generate-train-sample = "dotenv run python -m tools.run generate-train-sample"

# -------------------
# --- Model Serve ---
# -------------------

# serve the trained model locally using MLflow
# change port number if needed
serve-model-local = "poetry run python -m tools.serve --port 5000"

# Example curl command to call the served model
# change port number if needed
call-inference = '''
curl http://127.0.0.1:5000/invocations -H "Content-Type: application/json" --data
  '{
    "dataframe_split": {
      "columns": [
        "price_range",
        "state_id",
        "city",
        "density",
        "category",
        "ingredients",
        "cost_of_living_index"
      ],
      "data": [[
        "cheap",
        "Wisconsin",
        "appleton",
        1156,
        "Sandwiches",
        [
          "cheddar cheese",
          "applewood smoked bacon",
          "tomato",
          "lettuce",
          "bun",
          "maplebacon aioli",
          "chicken breast"
        ],
        49.94
      ]]
    }
  }'
'''

# -----------------------------------------------------
# --- ML Modelling (Training -> Tuning -> Register) ---
# -----------------------------------------------------

# ML pipeline tasks
[tool.poe.tasks.run-help]
cmd  = "python -m tools.run --help"
help = "Show help from the Restaurant Menu Pricing CLI (same as python -m tools.run -h)."

# List all available models
[tool.poe.tasks.models]
cmd = "dotenv run python -m tools.run --list-models"
help = "List all available models for training"

# Quick dry run to preview the execution plan (no training)
[tool.poe.tasks.dry-run]
cmd = "dotenv run python -m tools.run --dry-run"
help = "Show the planned models and config without executing training"

# Run the Restaurant CLI (forwards any flags to run.py)
# Full ML pipeline: tune all models, compare, and register best one
[tool.poe.tasks.run-pipeline]
cmd  = "dotenv run python -m tools.run"
help = "Run the Restaurant Menu Pricing CLI"
#help = "Run the full pipeline (tune all models, train, compare, and register the best model)"

# Run pipeline for specific models provided as arguments
[tool.poe.tasks.run-models]
cmd = "dotenv run python -m tools.run --models \"${models}\""
help = "Run the pipeline for specific models (e.g., poetry poe run-models lr,dtree or poetry poe run-models 'lr,dtree')"
args = [{ name = "models", positional = true, help = "Comma-separated model names (e.g. lr,dtree,xgboost)" }]

# Lightweight dev/test run with fewer trials/folds
[tool.poe.tasks.run-pipeline-dev]
cmd = "dotenv run python -m tools.run --n-trials 3 --cv-folds 2"
help = "Quick development run with minimal Optuna trials and CV folds"

# Full production run with heavier tuning
[tool.poe.tasks.run-pipeline-prod]
cmd = "dotenv run python -m tools.run --n-trials 50 --cv-folds 5"
help = "Full production-grade run with more trials and folds"

# -------------
# --- Tests ---
# -------------

[tool.poe.tasks.test]
cmd = "poetry run pytest tests/"

# -----------------------------
# --- Pytest Configuration ---
# -----------------------------

[tool.pytest.ini_options]
minversion = "8.0"
addopts = "-q -ra --disable-warnings --maxfail=1 --cov=."
testpaths = ["tests/unit", "tests/cli"]
markers = [
    "unit: fast unit tests (no IO/network)",
    "cli: tests that exercise the Click CLIs (tools.run / tools.serve)",
]

# ------------------------------
# --- Coverage Configuration ---
# ------------------------------
[tool.coverage.run]
source = ["."]
omit = [
    "tests/*",
    "bot/*",
    "model/*",
    "core/*",
    "pipelines/*",
]

[tool.coverage.report]
fail_under = 70
show_missing = true
skip_covered = true
